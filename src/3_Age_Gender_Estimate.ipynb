{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import argparse\n",
    "import inception_resnet_v1\n",
    "import tensorflow as tf\n",
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb\n",
    "from imutils import face_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_label(image, point, label, font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "              font_scale=1, thickness=2):\n",
    "    size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
    "    x, y = point\n",
    "    cv2.rectangle(image, (x, y, size[1]), (x + size[0], y), (255, 0, 0), cv2.FILLED)\n",
    "    cv2.putText(image, label, point, font, font_scale, (255, 255, 255), thickness=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model_path = \"../gender_age_tf/models/\"\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    images_pl = tf.placeholder(tf.float32, shape=[None, 160, 160, 3], name='input_image')\n",
    "    images_norm = tf.map_fn(lambda frame:\n",
    "                           tf.image.per_image_standardization(frame), images_pl)\n",
    "    train_mode = tf.placeholder(tf.bool)\n",
    "    age_logits, gender_logits, _ = inception_resnet_v1.inference(images_norm, keep_probability=0.8, phase_train=train_mode, weight_decay=1e-5)\n",
    "    \n",
    "    gender = tf.argmax(tf.nn.softmax(gender_logits), 1)\n",
    "    age_ = tf.cast(tf.constant([i for i in range(0, 101)]), tf.float32)\n",
    "    age = tf.reduce_sum(tf.multiply(tf.nn.softmax(age_logits), age_), axis=1)\n",
    "    init_op = tf.group(tf.global_variables_initializer(), \n",
    "                      tf.local_variables_initializer())\n",
    "    \n",
    "    sess.run(init_op)\n",
    "    saver = tf.train.Saver()\n",
    "    ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print(\"restore model!\")\n",
    "    else:\n",
    "        print(\"don't find model!\")\n",
    "    \n",
    "    \n",
    "    # Depth of network\n",
    "    depth = 16\n",
    "    \n",
    "    # width of network\n",
    "    width = 8\n",
    "    \n",
    "    # For face detection\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    fa_image = FaceAligner(predictor, desiredFaceWidth=160)\n",
    "    \n",
    "    img_size = 160\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    while True:\n",
    "        # get video frame\n",
    "        ret, img = cap.read()\n",
    "        \n",
    "#         if not ret:\n",
    "#             print(\"error: failed to capture image\")\n",
    "#             return -1\n",
    "        \n",
    "        input_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # height, width of image\n",
    "        img_h, img_w, _ = np.shape(input_img)\n",
    "        \n",
    "        # detect faces using dlib detector\n",
    "        detected = detector(gray, 1)\n",
    "        faces = np.empty((len(detected), img_size, img_size, 3))\n",
    "        #\n",
    "        for i, d in enumerate(detected): \n",
    "            # get axis position of face\n",
    "#             shape = predictor(gray, d)\n",
    "#             shape = face_utils.shape_to_np(shape)\n",
    "            \n",
    "#             # Compate eye right and eye left\n",
    "#             center_face = shape[37][1] - shape[46][1]\n",
    "#             print(center_face)\n",
    "#             if center_face < 10 & center_face > -10:\n",
    "            x1, y1, x2, y2, w, h = d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height()\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            faces[i, :, :, :] = fa_image.align(input_img, gray, detected[i])\n",
    "    # Detect face when the face is center\n",
    "        \n",
    "        if len(detected) > 0:\n",
    "            ages, genders = sess.run([age, gender], feed_dict={images_pl: faces})\n",
    "        \n",
    "        # draw results\n",
    "        for i, d in enumerate(detected):\n",
    "            label = \"{}, {}\".format(int(ages[i]), \"F\" if genders[i] == 0 else \"M\")\n",
    "            draw_label(img, (d.left(), d.top()), label)\n",
    "\n",
    "        cv2.imshow(\"result\", img)\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key == 27:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import argparse\n",
    "import inception_resnet_v1\n",
    "import tensorflow as tf\n",
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb\n",
    "from imutils import face_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_label(image, point, label, font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               font_scale=1, thickness=2):\n",
    "    size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
    "    x, y = point\n",
    "    cv2.rectangle(image, (x, y - size[1]), (x + size[0], y), (255, 0, 0), cv2.FILLED)\n",
    "    cv2.putText(image, label, point, font, font_scale, (255, 255, 255), thickness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(sess,age,gender,train_mode,images_pl):\n",
    "#     args = get_args()\n",
    "    depth = 16\n",
    "    k = 8\n",
    "\n",
    "    # for face detection\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    fa = FaceAligner(predictor, desiredFaceWidth=160)\n",
    "\n",
    "    # load model and weights\n",
    "    img_size = 160\n",
    "\n",
    "    # capture video\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    \n",
    "    num_frame = 0\n",
    "    \n",
    "    while True:\n",
    "        # get video frame\n",
    "        ret, img = cap.read()\n",
    "            \n",
    "        if not ret:\n",
    "            print(\"error: failed to capture image\")\n",
    "            return -1\n",
    "        num_frame += 1\n",
    "        \n",
    "        if num_frame % 3 == 0:\n",
    "            input_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img_h, img_w, _ = np.shape(input_img)\n",
    "\n",
    "            # detect faces using dlib detector\n",
    "            detected = detector(input_img, 1)\n",
    "            faces = np.empty((len(detected), img_size, img_size, 3))\n",
    "\n",
    "            for i, d in enumerate(detected):\n",
    "\n",
    "                shape = predictor(gray, d)\n",
    "                shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "                center_face = shape[37][1] - shape[46][1]\n",
    "                print(center_face)\n",
    "                if center_face < 20 and center_face > -20:\n",
    "                    x1, y1, x2, y2, w, h = d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height()\n",
    "        #             xw1 = max(int(x1 - 0.4 * w), 0)\n",
    "        #             yw1 = max(int(y1 - 0.4 * h), 0)\n",
    "        #             xw2 = min(int(x2 + 0.4 * w), img_w - 1)\n",
    "        #             yw2 = min(int(y2 + 0.4 * h), img_h - 1)\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    # cv2.rectangle(img, (xw1, yw1), (xw2, yw2), (255, 0, 0), 2)\n",
    "                    faces[i, :, :, :] = fa.align(input_img, gray, detected[i])\n",
    "                    # faces[i,:,:,:] = cv2.resize(img[yw1:yw2 + 1, xw1:xw2 + 1, :], (img_size, img_size))\n",
    "            #\n",
    "                    if len(detected) > 0:\n",
    "                        # predict ages and genders of the detected faces\n",
    "                        ages,genders = sess.run([age, gender], feed_dict={images_pl: faces, train_mode: False})\n",
    "\n",
    "                    # draw results\n",
    "                    for i, d in enumerate(detected):\n",
    "                        label = \"{}, {}\".format(int(ages[i]), \"F\" if genders[i] == 0 else \"M\")\n",
    "                        draw_label(img, (d.left(), d.top()), label)\n",
    "\n",
    "            cv2.imshow(\"result\", img)\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key == 27:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network(model_path):\n",
    "    sess = tf.Session()\n",
    "    images_pl = tf.placeholder(tf.float32, shape=[None, 160, 160, 3], name='input_image')\n",
    "    images_norm = tf.map_fn(lambda frame: tf.image.per_image_standardization(frame), images_pl)\n",
    "    train_mode = tf.placeholder(tf.bool)\n",
    "    age_logits, gender_logits, _ = inception_resnet_v1.inference(images_norm, keep_probability=0.8,\n",
    "                                                                 phase_train=train_mode,\n",
    "                                                                 weight_decay=1e-5)\n",
    "    gender = tf.argmax(tf.nn.softmax(gender_logits), 1)\n",
    "    age_ = tf.cast(tf.constant([i for i in range(0, 101)]), tf.float32)\n",
    "    age = tf.reduce_sum(tf.multiply(tf.nn.softmax(age_logits), age_), axis=1)\n",
    "    init_op = tf.group(tf.global_variables_initializer(),\n",
    "                       tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    saver = tf.train.Saver()\n",
    "    ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print(\"restore model!\")\n",
    "    else:\n",
    "        pass\n",
    "    return sess,age,gender,train_mode,images_pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../gender_age_tf/models/model.ckpt-14001\n",
      "restore model!\n",
      "-9\n",
      "-10\n",
      "-8\n",
      "-9\n",
      "-9\n",
      "-9\n",
      "-7\n",
      "-7\n",
      "-6\n",
      "-7\n",
      "-7\n",
      "-7\n",
      "-6\n",
      "-4\n",
      "-7\n",
      "-8\n",
      "-7\n",
      "-7\n",
      "-7\n",
      "-3\n",
      "-7\n",
      "-7\n",
      "-8\n",
      "-8\n",
      "-6\n",
      "-7\n",
      "-8\n",
      "-7\n",
      "-7\n",
      "-7\n",
      "-7\n",
      "-7\n",
      "-7\n",
      "-6\n",
      "-6\n",
      "-14\n",
      "-24\n",
      "-24\n",
      "-23\n",
      "-22\n",
      "-24\n",
      "-23\n",
      "-18\n",
      "-22\n",
      "-18\n",
      "-21\n",
      "-22\n",
      "-21\n",
      "-21\n",
      "-21\n",
      "-21\n",
      "-30\n",
      "-42\n",
      "-41\n",
      "-38\n",
      "-38\n",
      "-36\n",
      "-35\n",
      "-36\n",
      "-34\n",
      "-30\n",
      "-6\n",
      "14\n",
      "17\n",
      "19\n",
      "20\n",
      "19\n",
      "19\n",
      "24\n",
      "18\n",
      "19\n",
      "18\n",
      "17\n",
      "17\n",
      "18\n",
      "23\n",
      "18\n",
      "17\n",
      "19\n",
      "18\n",
      "8\n",
      "1\n",
      "-5\n",
      "-8\n",
      "-10\n",
      "-10\n",
      "-12\n",
      "-14\n",
      "-18\n",
      "-18\n",
      "-16\n",
      "-17\n",
      "-17\n",
      "-17\n",
      "-17\n",
      "-17\n",
      "-12\n",
      "-10\n",
      "-8\n",
      "-7\n",
      "-7\n",
      "-7\n",
      "-8\n",
      "-8\n",
      "-7\n",
      "-7\n",
      "-7\n",
      "-8\n",
      "-8\n",
      "-10\n",
      "-10\n",
      "-8\n",
      "-5\n",
      "-5\n",
      "-7\n",
      "-7\n",
      "-8\n",
      "-7\n",
      "-8\n",
      "-8\n",
      "-9\n",
      "-8\n",
      "-6\n",
      "-3\n",
      "-4\n",
      "-4\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-4\n",
      "-4\n",
      "-4\n",
      "-3\n",
      "-4\n",
      "-4\n",
      "-1\n",
      "-2\n",
      "-1\n",
      "-5\n",
      "-8\n",
      "-6\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-5\n",
      "-7\n",
      "-7\n",
      "-5\n",
      "-5\n",
      "-5\n",
      "-5\n",
      "-2\n",
      "-5\n",
      "-5\n",
      "-6\n",
      "-7\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-5\n",
      "-5\n",
      "-3\n",
      "-3\n",
      "-4\n",
      "-4\n",
      "-4\n",
      "-4\n",
      "-4\n",
      "-3\n",
      "-4\n",
      "-5\n",
      "-3\n",
      "-5\n",
      "-2\n",
      "-4\n",
      "-3\n",
      "-5\n",
      "-4\n",
      "-4\n",
      "-4\n",
      "-4\n",
      "-3\n",
      "-3\n",
      "-3\n",
      "-3\n",
      "-4\n",
      "-6\n",
      "-8\n",
      "0\n",
      "-10\n",
      "-4\n",
      "-13\n",
      "-7\n",
      "-5\n",
      "-12\n",
      "-11\n",
      "-15\n",
      "-16\n",
      "-11\n",
      "-13\n",
      "-8\n",
      "-14\n",
      "-13\n",
      "-15\n",
      "-18\n",
      "-15\n",
      "-22\n",
      "-19\n",
      "-20\n",
      "-5\n",
      "-7\n",
      "-10\n",
      "-10\n",
      "-7\n",
      "-7\n",
      "-8\n",
      "-6\n",
      "-5\n",
      "1\n",
      "-7\n",
      "-7\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-9\n",
      "-6\n",
      "-6\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-2\n",
      "-5\n",
      "-5\n",
      "-5\n",
      "-6\n",
      "3\n",
      "2\n",
      "2\n",
      "-3\n",
      "-7\n",
      "-3\n",
      "-10\n",
      "-4\n",
      "-5\n",
      "-6\n",
      "-6\n",
      "-4\n",
      "-5\n",
      "-7\n",
      "-3\n",
      "-3\n",
      "-5\n",
      "-6\n",
      "-3\n",
      "-8\n",
      "-11\n",
      "-13\n",
      "-11\n",
      "-12\n",
      "-16\n",
      "-15\n",
      "-11\n",
      "-11\n",
      "-9\n",
      "-9\n",
      "-7\n",
      "-3\n",
      "0\n",
      "-11\n",
      "-9\n",
      "-6\n",
      "-7\n",
      "-7\n",
      "-7\n",
      "-5\n",
      "-7\n",
      "-5\n",
      "-12\n",
      "-5\n",
      "-5\n",
      "-3\n",
      "-6\n",
      "-6\n",
      "5\n",
      "7\n",
      "-1\n",
      "-1\n",
      "-2\n",
      "-2\n",
      "-3\n",
      "-4\n",
      "-3\n",
      "-1\n",
      "-4\n",
      "-4\n",
      "-1\n",
      "-4\n",
      "-3\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "2\n",
      "-1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "4\n",
      "4\n",
      "7\n",
      "4\n",
      "4\n",
      "5\n",
      "-1\n",
      "-2\n",
      "-2\n",
      "-2\n",
      "-4\n",
      "-2\n",
      "-3\n",
      "-2\n",
      "-3\n",
      "-3\n",
      "-2\n",
      "-2\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "0\n",
      "-1\n",
      "1\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "7\n",
      "5\n",
      "7\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "14\n",
      "19\n",
      "15\n",
      "0\n",
      "4\n",
      "6\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\"--model_path\", \"--M\", default=\"./models\", type=str, help=\"Model Path\")\n",
    "#     args = parser.parse_args()\n",
    "    sess, age, gender, train_mode,images_pl = load_network(\"../gender_age_tf/models/\")\n",
    "    main(sess,age,gender,train_mode,images_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(tf.cast(tf.constant([i for i in range(0, 101)]), tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
